{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraping titulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_url = \"https://www.lavozdegalicia.es/coruna/\"\n",
    "response = requests.get(news_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "news_keys = ['title', 'news_image', 'news_href']\n",
    "    \n",
    "list_news = [\n",
    "    {\n",
    "        news_keys[0]: news.find(class_=\"a-min-content\").get_text(strip = True),\n",
    "        news_keys[1]: news.find(\"div\").find(\"img\").get(\"src\") if news.find(\"div\").find(\"img\") != None else None,\n",
    "        news_keys[2]: news_url+news.find(\"a\").get(\"href\")\n",
    "    }\n",
    "    for news in soup.find_all(class_=\"article-min\")]\n",
    "    \n",
    "list_news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_movies = \"https://www.sensacine.com/cines/cine/E0770/\"\n",
    "response = requests.get(url_movies)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "movie_keys = ['title','synopsis', 'image', 'link_ref']\n",
    "\n",
    "list_movies = [\n",
    "    {\n",
    "        movie_keys[0]: movie.find(class_=\"meta-title-link\").text,\n",
    "        movie_keys[1]: movie.find(class_=\"synopsis\").text.replace(\"\\n\", \"\"),\n",
    "        movie_keys[2]: movie.find(\"img\").get(\"src\") if movie.find(\"img\").get(\"src\").startswith(\"https\") else movie.find(\"img\").get(\"data-src\"),\n",
    "        movie_keys[3]: \"https://www.sensacine.com\" + movie.find(class_=\"meta-title-link\").get(\"href\")\n",
    "    }\n",
    "    for movie in soup.find_all(class_=\"movie-card-theater\")]\n",
    "\n",
    "list_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEB ORO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_feb = \"https://baloncestoenvivo.feb.es/resultados/ligaleboro/1/2023\"\n",
    "response = requests.get(url_feb)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find(id=\"_ctl0_MainContentPlaceHolderMaster_jornadaDataGrid\")\n",
    "\n",
    "match_list = []\n",
    "\n",
    "leb_match_keys = ['teams', 'result', 'date', 'time']\n",
    "\n",
    "for fila in table.find_all('tr')[1:]:\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for key, linha in zip(leb_match_keys, fila.find_all(['td', 'th'])):\n",
    "        temp_dict[key] = linha.get_text(strip=True)\n",
    "    \n",
    "    match_list.append(temp_dict)\n",
    "\n",
    "match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ladder = soup.find(id=\"_ctl0_MainContentPlaceHolderMaster_clasificacionDataGrid\")\n",
    "\n",
    "ladder_list = []\n",
    "\n",
    "leb_ladder_keys = ['POSITION', 'TEAMS', 'MATCHES_PLAYED', 'MATCHES_W', 'MATCHES_L', 'POINTS']\n",
    "\n",
    "for row in ladder.find_all('tr')[1:]:\n",
    "    temp_dict = {}\n",
    "\n",
    "    cells = row.find_all(['td', 'th'])\n",
    "    for key, cell in zip(leb_ladder_keys, cells):\n",
    "        if key == 'POINTS':\n",
    "            temp_dict[key] = cells[7].get_text(strip=True) \n",
    "        else:\n",
    "            temp_dict[key] = cell.get_text(strip=True)\n",
    "\n",
    "    ladder_list.append(temp_dict)\n",
    "\n",
    "df = pd.DataFrame(ladder_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.axis('off')\n",
    "\n",
    "col_widths = [0.1, 0.4, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center', colWidths=col_widths)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_feb = \"https://baloncestoenvivo.feb.es/resultados/ligaleboro/1/2023\"\n",
    "response = requests.get(url_feb)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find(id=\"_ctl0_MainContentPlaceHolderMaster_jornadaDataGrid\")\n",
    "\n",
    "match_list = []\n",
    "leb_match_keys = ['teams', 'result', 'date', 'time']\n",
    "\n",
    "# Iterar filas ignorando la primera\n",
    "for fila in table.find_all('tr')[1:]:\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for key, row in zip(leb_match_keys, fila.find_all(['td', 'th'])):\n",
    "        temp_dict[key] = row.get_text(strip=True).lower().title()\n",
    "    \n",
    "    match_list.append(temp_dict)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(match_list)\n",
    "fig, ax = plt.subplots(figsize=(1, 1))\n",
    "\n",
    "ax.axis('off')\n",
    "colors = ['lightgray', 'white']\n",
    "cell_colors = [[colors[i % 2] for _ in range(len(df.columns))] for i in range(len(df))]\n",
    "col_widths = [0.5, 0.1, 0.1, 0.1]\n",
    "\n",
    "ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center',cellColours=cell_colors, colWidths=col_widths)\n",
    "\n",
    "\n",
    "fig.set_size_inches(12, 2)\n",
    "fig.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_feb = \"https://baloncestoenvivo.feb.es/resultados/ligaleboro/1/2023\"\n",
    "response = requests.get(url_feb)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "ladder = soup.find(id=\"_ctl0_MainContentPlaceHolderMaster_clasificacionDataGrid\")\n",
    "\n",
    "ladder_list = []\n",
    "\n",
    "leb_ladder_keys = ['POSITION', 'TEAMS', 'MATCHES_PLAYED', 'MATCHES_W', 'MATCHES_L', 'POINTS']\n",
    "\n",
    "for row in ladder.find_all('tr')[1:]:\n",
    "    temp_dict = {}\n",
    "\n",
    "    cells = row.find_all(['td', 'th'])\n",
    "    for key, cell in zip(leb_ladder_keys, cells):\n",
    "        if key == 'POINTS':\n",
    "            temp_dict[key] = cells[7].get_text(strip=True) \n",
    "        else:\n",
    "            temp_dict[key] = cell.get_text(strip=True)\n",
    "\n",
    "    ladder_list.append(temp_dict)\n",
    "\n",
    "df = pd.DataFrame(ladder_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 3))\n",
    "ax.axis('off')\n",
    "\n",
    "col_widths = [0.1, 0.4, 0.2, 0.2, 0.2, 0.2]\n",
    "colors = ['lightgray', 'white']\n",
    "cell_colors = [[colors[i % 2] for _ in range(len(df.columns))] for i in range(len(df))]\n",
    "ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center', colWidths=col_widths, cellColours=cell_colors)\n",
    "\n",
    "fig.set_size_inches(12, 6)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistemas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
